{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C79KKN3pOavn"
      },
      "source": [
        "# Mini-RAG: Comparaci√≥n Qdrant vs Weaviate\n",
        "\n",
        "Este notebook implementa y compara dos sistemas Mini-RAG usando:\n",
        "- **Qdrant** como base de datos vectorial\n",
        "- **Weaviate** como base de datos vectorial\n",
        "- **FLAN-T5-small** como modelo de lenguaje para generaci√≥n\n",
        "- **all-MiniLM-L6-v2** para embeddings\n",
        "\n",
        "## Objetivos\n",
        "1. Construir Mini-RAG con ambas bases vectoriales\n",
        "2. Evaluar con m√©tricas P@k, R@k y nDCG@k\n",
        "3. Comparar rendimiento, latencia y facilidad de uso\n",
        "4. Implementar filtrado por metadatos y consultas h√≠bridas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y3fJFwxqOavp"
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n de dependencias\n",
        "!pip install -q qdrant-client weaviate-client sentence-transformers transformers accelerate pandas numpy scikit-learn tqdm rich\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLrYzrjLOavp",
        "outputId": "a12a4462-d12f-4599-bb1b-a3fdb881bdc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dependencias importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "# Imports necesarios\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Modelos y embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Bases de datos vectoriales\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models as qdrant_models\n",
        "import weaviate\n",
        "from weaviate.classes.config import Configure\n",
        "\n",
        "# M√©tricas\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Visualizaci√≥n\n",
        "from tqdm import tqdm\n",
        "from rich import print as rprint\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "\n",
        "console = Console()\n",
        "print(\"‚úÖ Dependencias importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iip5yho4Oavq"
      },
      "source": [
        "## 1. Configuraci√≥n de Modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8XDVg1hOavq",
        "outputId": "db1a00be-2cb4-4704-eda4-d9024c6d657f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Cargando modelos (esto puede tardar unos minutos)...\n",
            "‚úÖ Modelos cargados:\n",
            "   - Embeddings: sentence-transformers/all-MiniLM-L6-v2 (dim=384)\n",
            "   - Generaci√≥n: google/flan-t5-small\n"
          ]
        }
      ],
      "source": [
        "# Configuraci√≥n de modelos\n",
        "EMBED_MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "GEN_MODEL_NAME = 'google/flan-t5-small'\n",
        "\n",
        "print('üîÑ Cargando modelos (esto puede tardar unos minutos)...')\n",
        "\n",
        "# Modelo de embeddings\n",
        "embedder = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "embed_dim = embedder.get_sentence_embedding_dimension()\n",
        "\n",
        "# Modelo de generaci√≥n\n",
        "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
        "gen_model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL_NAME)\n",
        "\n",
        "print(f'‚úÖ Modelos cargados:')\n",
        "print(f'   - Embeddings: {EMBED_MODEL_NAME} (dim={embed_dim})')\n",
        "print(f'   - Generaci√≥n: {GEN_MODEL_NAME}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTKoq-ybOavq"
      },
      "source": [
        "## 2. Corpus de Documentos (30 documentos con metadatos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKXV_9s0Oavq",
        "outputId": "6d4c274d-e62a-4764-9544-fa908a2ad63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Corpus creado con 30 documentos\n",
            "üìä Categor√≠as: 12\n",
            "üìÖ Rango de fechas: 2023-03-30 - 2025-08-10\n"
          ]
        }
      ],
      "source": [
        "# Corpus de 30 documentos con metadatos completos\n",
        "docs = [\n",
        "    {\"id\": 1, \"title\": \"Inteligencia Artificial en Medicina\", \"text\": \"La IA se aplica en diagn√≥stico por im√°genes, an√°lisis de genomas y detecci√≥n temprana de enfermedades. Los algoritmos de aprendizaje autom√°tico pueden identificar patrones en radiograf√≠as, resonancias magn√©ticas y tomograf√≠as computarizadas.\", \"source\": \"Revista Salud Digital\", \"date\": \"2024-06-12\", \"category\": \"medicina\"},\n",
        "    {\"id\": 2, \"title\": \"Historia de la imprenta\", \"text\": \"La imprenta de Gutenberg revolucion√≥ la difusi√≥n del conocimiento en Europa desde el siglo XV. Esta innovaci√≥n permiti√≥ la producci√≥n masiva de libros y democratiz√≥ el acceso a la informaci√≥n.\", \"source\": \"Enciclopedia Hist√≥rica\", \"date\": \"2023-11-03\", \"category\": \"historia\"},\n",
        "    {\"id\": 3, \"title\": \"Beneficios del t√© verde\", \"text\": \"Contiene antioxidantes como catequinas que ayudan a reducir el estr√©s oxidativo y mejorar la salud cardiovascular. Estudios demuestran que el consumo regular puede reducir el riesgo de enfermedades card√≠acas.\", \"source\": \"Portal Nutrici√≥n y Vida\", \"date\": \"2025-01-15\", \"category\": \"salud\"},\n",
        "    {\"id\": 4, \"title\": \"Energ√≠a solar: ventajas y retos\", \"text\": \"Es renovable y limpia, pero depende del clima y requiere almacenamiento eficiente. Los paneles solares han reducido significativamente su costo en la √∫ltima d√©cada.\", \"source\": \"Energ√≠as del Futuro\", \"date\": \"2025-04-20\", \"category\": \"energia\"},\n",
        "    {\"id\": 5, \"title\": \"Resumen de la teor√≠a de la relatividad\", \"text\": \"Einstein propuso que el espacio-tiempo es curvo y que la gravedad es una manifestaci√≥n de esa curvatura. Esta teor√≠a revolucion√≥ nuestra comprensi√≥n del universo y llev√≥ a predicciones como la existencia de agujeros negros.\", \"source\": \"F√≠sica Moderna Hoy\", \"date\": \"2024-08-05\", \"category\": \"fisica\"},\n",
        "    {\"id\": 6, \"title\": \"¬øQu√© es el efecto placebo?\", \"text\": \"Una mejora en la salud causada por la creencia del paciente en un tratamiento sin efecto real. Este fen√≥meno demuestra la poderosa conexi√≥n entre mente y cuerpo en los procesos de curaci√≥n.\", \"source\": \"Psicolog√≠a Cl√≠nica\", \"date\": \"2023-12-01\", \"category\": \"medicina\"},\n",
        "    {\"id\": 7, \"title\": \"Las capas de la atm√≥sfera\", \"text\": \"Troposfera, estrat√≥sfera, mesosfera, termosfera y exosfera tienen distintas funciones y altitudes. Cada capa tiene caracter√≠sticas espec√≠ficas de temperatura, presi√≥n y composici√≥n qu√≠mica.\", \"source\": \"Clima y Ciencia\", \"date\": \"2024-03-30\", \"category\": \"ciencia\"},\n",
        "    {\"id\": 8, \"title\": \"Qu√© es el blockchain\", \"text\": \"Es una base de datos distribuida y segura que registra transacciones de forma inmutable. Esta tecnolog√≠a es la base de las criptomonedas y tiene aplicaciones en contratos inteligentes y trazabilidad.\", \"source\": \"Tech Diario\", \"date\": \"2025-06-01\", \"category\": \"tecnologia\"},\n",
        "    {\"id\": 9, \"title\": \"La fotos√≠ntesis explicada\", \"text\": \"Proceso por el cual las plantas convierten CO‚ÇÇ y luz solar en ox√≠geno y glucosa. Este proceso es fundamental para la vida en la Tierra ya que produce el ox√≠geno que respiramos.\", \"source\": \"Biolog√≠a B√°sica\", \"date\": \"2023-10-21\", \"category\": \"biologia\"},\n",
        "    {\"id\": 10, \"title\": \"Importancia de la lectura en la infancia\", \"text\": \"Fomenta el desarrollo del lenguaje, la empat√≠a y la capacidad de concentraci√≥n. Los ni√±os que leen regularmente desarrollan mejor vocabulario y habilidades de comprensi√≥n.\", \"source\": \"Educaci√≥n Hoy\", \"date\": \"2024-05-19\", \"category\": \"educacion\"},\n",
        "    {\"id\": 11, \"title\": \"Qu√© es el cambio clim√°tico\", \"text\": \"Se refiere al aumento sostenido de la temperatura global y sus efectos en el planeta. Las actividades humanas, especialmente la quema de combustibles f√≥siles, son la principal causa.\", \"source\": \"Observatorio Clim√°tico\", \"date\": \"2025-02-14\", \"category\": \"ambiente\"},\n",
        "    {\"id\": 12, \"title\": \"Origen del universo: Big Bang\", \"text\": \"El modelo del Big Bang plantea una expansi√≥n desde un estado extremadamente denso y caliente. Esta teor√≠a explica la formaci√≥n de elementos ligeros y la radiaci√≥n c√≥smica de fondo.\", \"source\": \"Astrof√≠sica para Todos\", \"date\": \"2024-07-07\", \"category\": \"fisica\"},\n",
        "    {\"id\": 13, \"title\": \"C√≥mo funciona un motor el√©ctrico\", \"text\": \"Convierte energ√≠a el√©ctrica en energ√≠a mec√°nica mediante fuerzas electromagn√©ticas. Los motores el√©ctricos son m√°s eficientes que los de combusti√≥n interna.\", \"source\": \"Ingenier√≠a 101\", \"date\": \"2024-09-11\", \"category\": \"tecnologia\"},\n",
        "    {\"id\": 14, \"title\": \"El Renacimiento en Europa\", \"text\": \"Movimiento cultural que valor√≥ la raz√≥n, el arte y la ciencia, con figuras como Da Vinci o Galileo. Este per√≠odo marc√≥ la transici√≥n de la Edad Media a la Edad Moderna.\", \"source\": \"Arte e Historia\", \"date\": \"2023-04-03\", \"category\": \"historia\"},\n",
        "    {\"id\": 15, \"title\": \"Python vs JavaScript\", \"text\": \"Python destaca en ciencia de datos, mientras que JavaScript domina en desarrollo web. Ambos lenguajes tienen ecosistemas ricos y comunidades activas.\", \"source\": \"Blog C√≥digo Abierto\", \"date\": \"2025-08-10\", \"category\": \"tecnologia\"},\n",
        "    {\"id\": 16, \"title\": \"Qu√© es el CO‚ÇÇ y por qu√© importa\", \"text\": \"Es un gas de efecto invernadero cuya acumulaci√≥n intensifica el calentamiento global. La concentraci√≥n atmosf√©rica de CO‚ÇÇ ha aumentado significativamente desde la revoluci√≥n industrial.\", \"source\": \"EcoMundo\", \"date\": \"2025-03-22\", \"category\": \"ambiente\"},\n",
        "    {\"id\": 17, \"title\": \"Neuroplasticidad: el cerebro que cambia\", \"text\": \"El cerebro puede reorganizarse y formar nuevas conexiones en respuesta al aprendizaje. Esta capacidad se mantiene durante toda la vida, aunque disminuye con la edad.\", \"source\": \"Revista Mente Abierta\", \"date\": \"2024-02-28\", \"category\": \"medicina\"},\n",
        "    {\"id\": 18, \"title\": \"Aportes de Marie Curie\", \"text\": \"Pionera en radioactividad, fue la primera persona en recibir dos premios Nobel. Sus investigaciones abrieron el camino para la medicina nuclear y la f√≠sica at√≥mica.\", \"source\": \"Cient√≠ficas que hicieron historia\", \"date\": \"2023-08-10\", \"category\": \"historia\"},\n",
        "    {\"id\": 19, \"title\": \"C√≥mo usar una br√∫jula\", \"text\": \"Una br√∫jula se√±ala el norte magn√©tico y ayuda en la orientaci√≥n geogr√°fica. Es una herramienta fundamental para la navegaci√≥n terrestre y mar√≠tima.\", \"source\": \"Manual de Supervivencia\", \"date\": \"2024-01-05\", \"category\": \"supervivencia\"},\n",
        "    {\"id\": 20, \"title\": \"Qu√© es una VPN y c√≥mo protege tu privacidad\", \"text\": \"Una VPN cifra tu conexi√≥n, ocultando tu IP y actividad en l√≠nea. Es especialmente √∫til cuando se conecta a redes WiFi p√∫blicas.\", \"source\": \"Seguridad Digital Hoy\", \"date\": \"2025-05-01\", \"category\": \"tecnologia\"},\n",
        "    {\"id\": 21, \"title\": \"Alimentos ricos en fibra\", \"text\": \"Legumbres, frutas, cereales integrales y semillas favorecen la digesti√≥n y la salud intestinal. Una dieta rica en fibra puede prevenir enfermedades cardiovasculares.\", \"source\": \"Gu√≠a Nutricional\", \"date\": \"2024-11-09\", \"category\": \"salud\"},\n",
        "    {\"id\": 22, \"title\": \"Fases de la Luna\", \"text\": \"Incluyen luna nueva, cuarto creciente, luna llena y cuarto menguante, en un ciclo de ~29 d√≠as. Estas fases han sido utilizadas por civilizaciones para medir el tiempo.\", \"source\": \"Astronom√≠a B√°sica\", \"date\": \"2023-09-12\", \"category\": \"ciencia\"},\n",
        "    {\"id\": 23, \"title\": \"¬øQu√© es el machine learning?\", \"text\": \"Es una rama de la IA donde los algoritmos aprenden patrones a partir de datos. Se aplica en reconocimiento de im√°genes, procesamiento de lenguaje natural y sistemas de recomendaci√≥n.\", \"source\": \"Aprendizaje Autom√°tico Hoy\", \"date\": \"2025-07-17\", \"category\": \"tecnologia\"},\n",
        "    {\"id\": 24, \"title\": \"El alfabeto griego\", \"text\": \"Usado en matem√°ticas y ciencia, contiene letras como alfa, beta, gamma y delta. Muchas constantes y variables cient√≠ficas utilizan letras griegas.\", \"source\": \"Lenguas Antiguas\", \"date\": \"2023-03-30\", \"category\": \"educacion\"},\n",
        "    {\"id\": 25, \"title\": \"C√≥mo se forma un arco√≠ris\", \"text\": \"La luz solar se refracta y refleja dentro de gotas de agua, separando colores por longitud de onda. Este fen√≥meno √≥ptico requiere sol y lluvia simult√°neamente.\", \"source\": \"F√≠sica Natural\", \"date\": \"2024-04-15\", \"category\": \"fisica\"},\n",
        "    {\"id\": 26, \"title\": \"Importancia de los polinizadores\", \"text\": \"Abejas, mariposas y aves ayudan en la reproducci√≥n de plantas y producci√≥n de alimentos. Sin polinizadores, muchos cultivos no podr√≠an reproducirse.\", \"source\": \"Biodiversidad Global\", \"date\": \"2025-03-10\", \"category\": \"biologia\"},\n",
        "    {\"id\": 27, \"title\": \"Ventajas del ejercicio regular\", \"text\": \"Reduce el riesgo de enfermedades, mejora el estado de √°nimo y fortalece el sistema inmune. La OMS recomienda al menos 150 minutos de ejercicio moderado por semana.\", \"source\": \"Salud Activa\", \"date\": \"2024-12-18\", \"category\": \"salud\"},\n",
        "    {\"id\": 28, \"title\": \"¬øQu√© es una estrella fugaz?\", \"text\": \"Es un meteoro que arde al entrar en la atm√≥sfera terrestre, creando un brillo breve. La mayor√≠a son part√≠culas de polvo c√≥smico del tama√±o de granos de arena.\", \"source\": \"Curiosidades del Espacio\", \"date\": \"2023-06-06\", \"category\": \"ciencia\"},\n",
        "    {\"id\": 29, \"title\": \"C√©lulas madre: usos m√©dicos\", \"text\": \"Las c√©lulas madre pueden regenerar tejidos, tratar enfermedades como leucemia y formar la base de terapias regenerativas. Representan una esperanza para tratar enfermedades degenerativas.\", \"source\": \"Medicina del Futuro\", \"date\": \"2024-10-02\", \"category\": \"medicina\"},\n",
        "    {\"id\": 30, \"title\": \"¬øQu√© es la econom√≠a circular?\", \"text\": \"Es un modelo econ√≥mico que busca reducir residuos reutilizando, reciclando y prolongando la vida de los productos. Contrasta con el modelo lineal de 'usar y tirar'.\", \"source\": \"Econom√≠a Sostenible\", \"date\": \"2025-08-01\", \"category\": \"economia\"}\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Corpus creado con {len(docs)} documentos\")\n",
        "print(f\"üìä Categor√≠as: {len(set(d['category'] for d in docs))}\")\n",
        "print(f\"üìÖ Rango de fechas: {min(d['date'] for d in docs)} - {max(d['date'] for d in docs)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omMInxt7Oavr"
      },
      "source": [
        "## 3. Funciones Auxiliares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZvBqYm_Oavr",
        "outputId": "7c7a31d9-1ab6-4f9c-aa76-886a24482ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funciones auxiliares definidas\n"
          ]
        }
      ],
      "source": [
        "def embed_texts(texts: List[str]) -> np.ndarray:\n",
        "    \"\"\"Genera embeddings para una lista de textos\"\"\"\n",
        "    vecs = embedder.encode(texts, show_progress_bar=False, convert_to_numpy=True)\n",
        "    return normalize(vecs)\n",
        "\n",
        "def generate_answer(prompt: str, max_length: int = 128) -> str:\n",
        "    \"\"\"Genera respuesta usando FLAN-T5\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=512)\n",
        "    outputs = gen_model.generate(**inputs, max_length=max_length, do_sample=False)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def chunk_text(text: str, max_tokens: int = 90) -> List[str]:\n",
        "    \"\"\"Divide texto en chunks por palabras\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), max_tokens):\n",
        "        chunk = \" \".join(words[i:i+max_tokens])\n",
        "        if chunk.strip():\n",
        "            chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "print(\"‚úÖ Funciones auxiliares definidas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzVyjrrvOavr"
      },
      "source": [
        "## 4. Preguntas de Prueba con Ground Truth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru5waz6eOavr",
        "outputId": "939e1662-2a66-4f42-dd97-7e454a79aafe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 10 preguntas de prueba definidas\n",
            "üìù Categor√≠as cubiertas: {'ambiente', 'economia', 'biologia', 'ciencia', 'fisica', 'salud', 'medicina', 'tecnologia'}\n"
          ]
        }
      ],
      "source": [
        "# 10 preguntas de prueba con documentos relevantes identificados\n",
        "test_queries = [\n",
        "    {\n",
        "        \"question\": \"¬øEn qu√© √°reas de la medicina se usa la inteligencia artificial?\",\n",
        "        \"relevant_docs\": [1],  # Inteligencia Artificial en Medicina\n",
        "        \"category\": \"medicina\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øCu√°l es la funci√≥n principal de la fotos√≠ntesis?\",\n",
        "        \"relevant_docs\": [9],  # La fotos√≠ntesis explicada\n",
        "        \"category\": \"biologia\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øQu√© propone la teor√≠a del Big Bang sobre el origen del universo?\",\n",
        "        \"relevant_docs\": [12],  # Origen del universo: Big Bang\n",
        "        \"category\": \"fisica\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øCu√°les son las capas de la atm√≥sfera terrestre?\",\n",
        "        \"relevant_docs\": [7],  # Las capas de la atm√≥sfera\n",
        "        \"category\": \"ciencia\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øQu√© es una VPN y c√≥mo protege la privacidad?\",\n",
        "        \"relevant_docs\": [20],  # Qu√© es una VPN y c√≥mo protege tu privacidad\n",
        "        \"category\": \"tecnologia\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øCu√°les son los beneficios del t√© verde para la salud?\",\n",
        "        \"relevant_docs\": [3],  # Beneficios del t√© verde\n",
        "        \"category\": \"salud\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øPara qu√© se utilizan las c√©lulas madre en medicina?\",\n",
        "        \"relevant_docs\": [29],  # C√©lulas madre: usos m√©dicos\n",
        "        \"category\": \"medicina\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øQu√© es el efecto placebo y c√≥mo funciona?\",\n",
        "        \"relevant_docs\": [6],  # ¬øQu√© es el efecto placebo?\n",
        "        \"category\": \"medicina\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øC√≥mo afecta el CO‚ÇÇ al cambio clim√°tico?\",\n",
        "        \"relevant_docs\": [16, 11],  # CO‚ÇÇ y cambio clim√°tico\n",
        "        \"category\": \"ambiente\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"¬øQu√© es la econom√≠a circular y c√≥mo funciona?\",\n",
        "        \"relevant_docs\": [30],  # ¬øQu√© es la econom√≠a circular?\n",
        "        \"category\": \"economia\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ {len(test_queries)} preguntas de prueba definidas\")\n",
        "print(f\"üìù Categor√≠as cubiertas: {set(q['category'] for q in test_queries)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5b0lxOsOavs"
      },
      "source": [
        "## 5. M√©tricas de Evaluaci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MusU0GYgOavs",
        "outputId": "ba9d06ba-d630-4141-a1f4-5fed38ea90e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ M√©tricas de evaluaci√≥n implementadas\n"
          ]
        }
      ],
      "source": [
        "def precision_at_k(retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calcula Precision@k\"\"\"\n",
        "    retrieved_k = retrieved_ids[:k]\n",
        "    relevant_retrieved = sum(1 for doc_id in retrieved_k if doc_id in relevant_ids)\n",
        "    return relevant_retrieved / k if k > 0 else 0.0\n",
        "\n",
        "def recall_at_k(retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calcula Recall@k\"\"\"\n",
        "    retrieved_k = retrieved_ids[:k]\n",
        "    relevant_retrieved = sum(1 for doc_id in retrieved_k if doc_id in relevant_ids)\n",
        "    return relevant_retrieved / len(relevant_ids) if len(relevant_ids) > 0 else 0.0\n",
        "\n",
        "def ndcg_at_k(retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calcula nDCG@k usando relevancia binaria\"\"\"\n",
        "    retrieved_k = retrieved_ids[:k]\n",
        "\n",
        "    # Calcular DCG\n",
        "    dcg = 0.0\n",
        "    for i, doc_id in enumerate(retrieved_k):\n",
        "        if doc_id in relevant_ids:\n",
        "            dcg += 1.0 / np.log2(i + 2)  # +2 porque log2(1) = 0\n",
        "\n",
        "    # Calcular IDCG (mejor ordenamiento posible)\n",
        "    idcg = 0.0\n",
        "    for i in range(min(len(relevant_ids), k)):\n",
        "        idcg += 1.0 / np.log2(i + 2)\n",
        "\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "print(\"‚úÖ M√©tricas de evaluaci√≥n implementadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfAG74c3Oavs"
      },
      "source": [
        "## 6. Implementaci√≥n Mini-RAG con Qdrant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDTC4K37Oavs",
        "outputId": "eefd76e6-62ae-4a71-be95-86899e26f061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Qdrant configurado: colecci√≥n 'mini_rag_docs' creada\n"
          ]
        }
      ],
      "source": [
        "# Configurar cliente Qdrant (modo embebido)\n",
        "DB_PATH = \"/tmp/qdrant_db\"\n",
        "qdrant_client = QdrantClient(path=DB_PATH)\n",
        "QDRANT_COLLECTION = \"mini_rag_docs\"\n",
        "\n",
        "# Recrear colecci√≥n\n",
        "try:\n",
        "    qdrant_client.delete_collection(QDRANT_COLLECTION)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "qdrant_client.create_collection(\n",
        "    collection_name=QDRANT_COLLECTION,\n",
        "    vectors_config=qdrant_models.VectorParams(\n",
        "        size=embed_dim,\n",
        "        distance=qdrant_models.Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Qdrant configurado: colecci√≥n '{QDRANT_COLLECTION}' creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqqFbosaOavs",
        "outputId": "84557ef7-0166-42fb-efbb-e2e1157d150b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Indexando en Qdrant: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 47.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 30 documentos indexados en Qdrant\n"
          ]
        }
      ],
      "source": [
        "# Indexar documentos en Qdrant\n",
        "points = []\n",
        "point_id = 1\n",
        "\n",
        "for doc in tqdm(docs, desc=\"Indexando en Qdrant\"):\n",
        "    # Crear contenido completo\n",
        "    full_text = f\"{doc['title']}. {doc['text']}\"\n",
        "\n",
        "    # Generar embedding\n",
        "    embedding = embedder.encode(full_text, normalize_embeddings=True)\n",
        "\n",
        "    # Crear punto\n",
        "    point = qdrant_models.PointStruct(\n",
        "        id=point_id,\n",
        "        vector=embedding.tolist(),\n",
        "        payload={\n",
        "            \"doc_id\": doc[\"id\"],\n",
        "            \"title\": doc[\"title\"],\n",
        "            \"text\": doc[\"text\"],\n",
        "            \"source\": doc[\"source\"],\n",
        "            \"date\": doc[\"date\"],\n",
        "            \"category\": doc[\"category\"],\n",
        "            \"full_text\": full_text\n",
        "        }\n",
        "    )\n",
        "    points.append(point)\n",
        "    point_id += 1\n",
        "\n",
        "# Insertar todos los puntos\n",
        "qdrant_client.upsert(collection_name=QDRANT_COLLECTION, points=points)\n",
        "\n",
        "# Verificar inserci√≥n\n",
        "count = qdrant_client.count(collection_name=QDRANT_COLLECTION).count\n",
        "print(f\"‚úÖ {count} documentos indexados en Qdrant\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwzhGVZrOavs"
      },
      "source": [
        "## 7. Implementaci√≥n Mini-RAG con Weaviate (Simulado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQsEF_HiOavs",
        "outputId": "b8739cb8-abed-4461-a430-8381661021aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Indexando en Weaviate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 30 documentos indexados en Weaviate (simulado)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Implementaci√≥n simulada de Weaviate para comparaci√≥n\n",
        "class MockWeaviate:\n",
        "    def __init__(self):\n",
        "        self.vectors = None\n",
        "        self.documents = []\n",
        "        self.embeddings = []\n",
        "\n",
        "    def add_documents(self, docs, embeddings):\n",
        "        self.documents = docs\n",
        "        self.embeddings = np.array(embeddings)\n",
        "        print(f\"‚úÖ {len(docs)} documentos indexados en Weaviate (simulado)\")\n",
        "\n",
        "    def search(self, query_vector, k=5, filters=None):\n",
        "        \"\"\"B√∫squeda por similitud coseno con filtros opcionales\"\"\"\n",
        "        similarities = np.dot(self.embeddings, query_vector.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Aplicar filtros si existen\n",
        "        valid_indices = np.arange(len(self.documents))\n",
        "        if filters:\n",
        "            mask = np.ones(len(self.documents), dtype=bool)\n",
        "            for key, value in filters.items():\n",
        "                if isinstance(value, tuple) and len(value) == 2:  # Rango de fechas\n",
        "                    dates = [doc[key] for doc in self.documents]\n",
        "                    mask &= np.array([(d >= value[0] and d <= value[1]) for d in dates])\n",
        "                else:  # Igualdad exacta\n",
        "                    values = [doc.get(key) for doc in self.documents]\n",
        "                    mask &= np.array([v == value for v in values])\n",
        "            valid_indices = valid_indices[mask]\n",
        "            similarities = similarities[mask]\n",
        "\n",
        "        # Obtener top-k\n",
        "        if len(similarities) == 0:\n",
        "            return []\n",
        "\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            actual_idx = valid_indices[idx] if filters else idx\n",
        "            results.append({\n",
        "                'doc_id': self.documents[actual_idx]['id'],\n",
        "                'score': float(similarities[idx]),\n",
        "                'title': self.documents[actual_idx]['title'],\n",
        "                'text': self.documents[actual_idx]['text'],\n",
        "                'source': self.documents[actual_idx]['source'],\n",
        "                'category': self.documents[actual_idx]['category']\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "# Crear e indexar en Weaviate simulado\n",
        "mock_weaviate = MockWeaviate()\n",
        "\n",
        "# Generar embeddings para todos los documentos\n",
        "weaviate_embeddings = []\n",
        "for doc in tqdm(docs, desc=\"Indexando en Weaviate\"):\n",
        "    full_text = f\"{doc['title']}. {doc['text']}\"\n",
        "    embedding = embedder.encode(full_text, normalize_embeddings=True)\n",
        "    weaviate_embeddings.append(embedding)\n",
        "\n",
        "mock_weaviate.add_documents(docs, weaviate_embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bPo6hnLOavt"
      },
      "source": [
        "## 8. Clases RAG para Ambos Sistemas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib_6A0SzOavt",
        "outputId": "1165792b-9290-4bfd-b150-c06f17cd4f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Clases RAG implementadas\n"
          ]
        }
      ],
      "source": [
        "class QdrantRAG:\n",
        "    def __init__(self, client, collection_name):\n",
        "        self.client = client\n",
        "        self.collection_name = collection_name\n",
        "\n",
        "    def search(self, query: str, k: int = 5, filters: Optional[Dict] = None) -> Tuple[List[Dict], float]:\n",
        "        \"\"\"B√∫squeda sem√°ntica con filtros opcionales\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Generar embedding de la consulta\n",
        "        query_vector = embedder.encode(query, normalize_embeddings=True).tolist()\n",
        "\n",
        "        # Construir filtros de Qdrant\n",
        "        qdrant_filter = None\n",
        "        if filters:\n",
        "            conditions = []\n",
        "            for key, value in filters.items():\n",
        "                if isinstance(value, tuple) and len(value) == 2:  # Rango de fechas\n",
        "                    # Convert date strings to timestamps for Qdrant filtering\n",
        "                    try:\n",
        "                        start_timestamp = datetime.strptime(value[0], '%Y-%m-%d').timestamp()\n",
        "                        end_timestamp = datetime.strptime(value[1], '%Y-%m-%d').timestamp()\n",
        "                        conditions.append(\n",
        "                            qdrant_models.FieldCondition(\n",
        "                                key=key,\n",
        "                                range=qdrant_models.Range(gte=start_timestamp, lte=end_timestamp)\n",
        "                            )\n",
        "                        )\n",
        "                    except ValueError:\n",
        "                        print(f\"Error: Invalid date format in filter for key '{key}'. Expected YYYY-MM-DD.\")\n",
        "                        continue\n",
        "                else:  # Igualdad exacta\n",
        "                    conditions.append(\n",
        "                        qdrant_models.FieldCondition(\n",
        "                            key=key,\n",
        "                            match=qdrant_models.MatchValue(value=value)\n",
        "                        )\n",
        "                    )\n",
        "            if conditions:\n",
        "                qdrant_filter = qdrant_models.Filter(must=conditions)\n",
        "\n",
        "        # Realizar b√∫squeda\n",
        "        hits = self.client.query_points(\n",
        "            collection_name=self.collection_name,\n",
        "            query=query_vector,\n",
        "            query_filter=qdrant_filter,\n",
        "            limit=k,\n",
        "            with_payload=True\n",
        "        ).points\n",
        "\n",
        "        search_time = time.time() - start_time\n",
        "\n",
        "        results = []\n",
        "        for hit in hits:\n",
        "            results.append({\n",
        "                \"doc_id\": hit.payload[\"doc_id\"],\n",
        "                \"score\": hit.score,\n",
        "                \"title\": hit.payload[\"title\"],\n",
        "                \"text\": hit.payload[\"text\"],\n",
        "                \"source\": hit.payload[\"source\"],\n",
        "                \"category\": hit.payload[\"category\"]\n",
        "            })\n",
        "\n",
        "        return results, search_time\n",
        "\n",
        "    def query(self, question: str, k: int = 3, filters: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"Consulta completa RAG: b√∫squeda + generaci√≥n\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # B√∫squeda\n",
        "        search_results, search_time = self.search(question, k=k, filters=filters)\n",
        "\n",
        "        if not search_results:\n",
        "            return {\n",
        "                \"answer\": \"No encontr√© informaci√≥n relevante.\",\n",
        "                \"sources\": [],\n",
        "                \"search_results\": [],\n",
        "                \"search_time\": search_time,\n",
        "                \"total_time\": time.time() - start_time\n",
        "            }\n",
        "\n",
        "        # Construir contexto\n",
        "        context_parts = []\n",
        "        for result in search_results:\n",
        "            context_parts.append(f\"T√≠tulo: {result['title']}\\\\nTexto: {result['text']}\")\n",
        "\n",
        "        context = \"\\\\n\\\\n\".join(context_parts)\n",
        "\n",
        "        # Crear prompt\n",
        "        prompt = f\"\"\"Responde la pregunta usando solo la informaci√≥n proporcionada. S√© conciso y preciso.\n",
        "\n",
        "Informaci√≥n:\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "        # Generar respuesta\n",
        "        answer = generate_answer(prompt, max_length=150)\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"sources\": list(set([r[\"source\"] for r in search_results])),\n",
        "            \"search_results\": search_results,\n",
        "            \"search_time\": search_time,\n",
        "            \"total_time\": time.time() - start_time\n",
        "        }\n",
        "\n",
        "class WeaviateRAG:\n",
        "    def __init__(self, mock_client):\n",
        "        self.client = mock_client\n",
        "\n",
        "    def search(self, query: str, k: int = 5, filters: Optional[Dict] = None) -> Tuple[List[Dict], float]:\n",
        "        \"\"\"B√∫squeda sem√°ntica con filtros opcionales\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Generar embedding de la consulta\n",
        "        query_vector = embedder.encode(query, normalize_embeddings=True)\n",
        "\n",
        "        # Realizar b√∫squeda\n",
        "        results = self.client.search(query_vector, k=k, filters=filters)\n",
        "\n",
        "        search_time = time.time() - start_time\n",
        "        return results, search_time\n",
        "\n",
        "    def query(self, question: str, k: int = 3, filters: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"Consulta completa RAG: b√∫squeda + generaci√≥n\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # B√∫squeda\n",
        "        search_results, search_time = self.search(question, k=k, filters=filters)\n",
        "\n",
        "        if not search_results:\n",
        "            return {\n",
        "                \"answer\": \"No encontr√© informaci√≥n relevante.\",\n",
        "                \"sources\": [],\n",
        "                \"search_results\": [],\n",
        "                \"search_time\": search_time,\n",
        "                \"total_time\": time.time() - start_time\n",
        "            }\n",
        "\n",
        "        # Construir contexto\n",
        "        context_parts = []\n",
        "        for result in search_results:\n",
        "            context_parts.append(f\"T√≠tulo: {result['title']}\\\\nTexto: {result['text']}\")\n",
        "\n",
        "        context = \"\\\\n\\\\n\".join(context_parts)\n",
        "\n",
        "        # Crear prompt\n",
        "        prompt = f\"\"\"Responde la pregunta usando solo la informaci√≥n proporcionada. S√© conciso y preciso.\n",
        "\n",
        "Informaci√≥n:\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "        # Generar respuesta\n",
        "        answer = generate_answer(prompt, max_length=150)\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"sources\": list(set([r[\"source\"] for r in search_results])),\n",
        "            \"search_results\": search_results,\n",
        "            \"search_time\": search_time,\n",
        "            \"total_time\": time.time() - start_time\n",
        "        }\n",
        "\n",
        "# Crear instancias RAG\n",
        "qdrant_rag = QdrantRAG(qdrant_client, QDRANT_COLLECTION)\n",
        "weaviate_rag = WeaviateRAG(mock_weaviate)\n",
        "\n",
        "print(\"‚úÖ Clases RAG implementadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJpXiAutOavt"
      },
      "source": [
        "## 9. Evaluaci√≥n Completa y Comparaci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz1jlxUFOavt",
        "outputId": "86d4b09a-83ed-404b-eaf5-be37f09d0ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Iniciando evaluaci√≥n con k=5...\\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluando Qdrant: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:57<00:00,  5.72s/it]\n",
            "Evaluando Weaviate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:36<00:00,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Evaluaci√≥n completada\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_rag_system(rag_system, system_name: str, test_queries: List[Dict], k: int = 5) -> Dict:\n",
        "    \"\"\"Eval√∫a un sistema RAG con las m√©tricas definidas\"\"\"\n",
        "    results = {\n",
        "        \"system_name\": system_name,\n",
        "        \"queries\": [],\n",
        "        \"metrics\": {\n",
        "            \"precision_at_k\": [],\n",
        "            \"recall_at_k\": [],\n",
        "            \"ndcg_at_k\": [],\n",
        "            \"search_times\": [],\n",
        "            \"total_times\": []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for query_data in tqdm(test_queries, desc=f\"Evaluando {system_name}\"):\n",
        "        question = query_data[\"question\"]\n",
        "        relevant_docs = query_data[\"relevant_docs\"]\n",
        "\n",
        "        # Ejecutar consulta\n",
        "        response = rag_system.query(question, k=k)\n",
        "\n",
        "        # Extraer IDs de documentos recuperados\n",
        "        retrieved_ids = [result[\"doc_id\"] for result in response[\"search_results\"]]\n",
        "\n",
        "        # Calcular m√©tricas\n",
        "        p_at_k = precision_at_k(retrieved_ids, relevant_docs, k)\n",
        "        r_at_k = recall_at_k(retrieved_ids, relevant_docs, k)\n",
        "        ndcg = ndcg_at_k(retrieved_ids, relevant_docs, k)\n",
        "\n",
        "        # Obtener tiempos\n",
        "        search_time = response[\"search_time\"]\n",
        "        total_time = response[\"total_time\"]\n",
        "\n",
        "        # Guardar resultados de la consulta\n",
        "        query_result = {\n",
        "            \"question\": question,\n",
        "            \"relevant_docs\": relevant_docs,\n",
        "            \"retrieved_docs\": retrieved_ids,\n",
        "            \"answer\": response[\"answer\"],\n",
        "            \"sources\": response[\"sources\"],\n",
        "            \"precision_at_k\": p_at_k,\n",
        "            \"recall_at_k\": r_at_k,\n",
        "            \"ndcg_at_k\": ndcg,\n",
        "            \"search_time\": search_time,\n",
        "            \"total_time\": total_time\n",
        "        }\n",
        "\n",
        "        results[\"queries\"].append(query_result)\n",
        "        results[\"metrics\"][\"precision_at_k\"].append(p_at_k)\n",
        "        results[\"metrics\"][\"recall_at_k\"].append(r_at_k)\n",
        "        results[\"metrics\"][\"ndcg_at_k\"].append(ndcg)\n",
        "        results[\"metrics\"][\"search_times\"].append(search_time)\n",
        "        results[\"metrics\"][\"total_times\"].append(total_time)\n",
        "\n",
        "    # Calcular promedios\n",
        "    results[\"avg_metrics\"] = {\n",
        "        \"avg_precision_at_k\": np.mean(results[\"metrics\"][\"precision_at_k\"]),\n",
        "        \"avg_recall_at_k\": np.mean(results[\"metrics\"][\"recall_at_k\"]),\n",
        "        \"avg_ndcg_at_k\": np.mean(results[\"metrics\"][\"ndcg_at_k\"]),\n",
        "        \"avg_search_time\": np.mean(results[\"metrics\"][\"search_times\"]),\n",
        "        \"avg_total_time\": np.mean(results[\"metrics\"][\"total_times\"])\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejecutar evaluaciones\n",
        "K = 5\n",
        "print(f\"üîÑ Iniciando evaluaci√≥n con k={K}...\\\\n\")\n",
        "\n",
        "qdrant_results = evaluate_rag_system(qdrant_rag, \"Qdrant\", test_queries, k=K)\n",
        "weaviate_results = evaluate_rag_system(weaviate_rag, \"Weaviate\", test_queries, k=K)\n",
        "\n",
        "print(\"‚úÖ Evaluaci√≥n completada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQAXYPVNOavt"
      },
      "source": [
        "## 10. Tabla Comparativa de Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "zrZHL7M4Oavt",
        "outputId": "b7f92c54-6693-4e76-c1ce-04c46afe7caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä TABLA COMPARATIVA - QDRANT VS WEAVIATE\n",
            "================================================================================\n",
            " Sistema   P@5   R@5 nDCG@5 Latencia B√∫squeda (ms) Tiempo Total (ms)\n",
            "  Qdrant 0.220 1.000  0.926                   28.0            5713.3\n",
            "Weaviate 0.220 1.000  0.926                    9.0            3639.8\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                          Comparaci√≥n Qdrant vs Weaviate                          \u001b[0m\n",
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mSistema \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m  P@5\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m  R@5\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mnDCG@5\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mLatencia B√∫squeda (ms)\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mTiempo Total (ms)\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[36m \u001b[0m\u001b[36mQdrant  \u001b[0m\u001b[36m \u001b[0m‚îÇ 0.220 ‚îÇ 1.000 ‚îÇ  0.926 ‚îÇ                   28.0 ‚îÇ            5713.3 ‚îÇ\n",
              "‚îÇ\u001b[36m \u001b[0m\u001b[36mWeaviate\u001b[0m\u001b[36m \u001b[0m‚îÇ 0.220 ‚îÇ 1.000 ‚îÇ  0.926 ‚îÇ                    9.0 ‚îÇ            3639.8 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                          Comparaci√≥n Qdrant vs Weaviate                          </span>\n",
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Sistema  </span>‚îÉ<span style=\"font-weight: bold\">   P@5 </span>‚îÉ<span style=\"font-weight: bold\">   R@5 </span>‚îÉ<span style=\"font-weight: bold\"> nDCG@5 </span>‚îÉ<span style=\"font-weight: bold\"> Latencia B√∫squeda (ms) </span>‚îÉ<span style=\"font-weight: bold\"> Tiempo Total (ms) </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> Qdrant   </span>‚îÇ 0.220 ‚îÇ 1.000 ‚îÇ  0.926 ‚îÇ                   28.0 ‚îÇ            5713.3 ‚îÇ\n",
              "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> Weaviate </span>‚îÇ 0.220 ‚îÇ 1.000 ‚îÇ  0.926 ‚îÇ                    9.0 ‚îÇ            3639.8 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Crear tabla comparativa\n",
        "comparison_df = pd.DataFrame([\n",
        "    {\n",
        "        \"Sistema\": \"Qdrant\",\n",
        "        \"P@5\": f\"{qdrant_results['avg_metrics']['avg_precision_at_k']:.3f}\",\n",
        "        \"R@5\": f\"{qdrant_results['avg_metrics']['avg_recall_at_k']:.3f}\",\n",
        "        \"nDCG@5\": f\"{qdrant_results['avg_metrics']['avg_ndcg_at_k']:.3f}\",\n",
        "        \"Latencia B√∫squeda (ms)\": f\"{qdrant_results['avg_metrics']['avg_search_time']*1000:.1f}\",\n",
        "        \"Tiempo Total (ms)\": f\"{qdrant_results['avg_metrics']['avg_total_time']*1000:.1f}\"\n",
        "    },\n",
        "    {\n",
        "        \"Sistema\": \"Weaviate\",\n",
        "        \"P@5\": f\"{weaviate_results['avg_metrics']['avg_precision_at_k']:.3f}\",\n",
        "        \"R@5\": f\"{weaviate_results['avg_metrics']['avg_recall_at_k']:.3f}\",\n",
        "        \"nDCG@5\": f\"{weaviate_results['avg_metrics']['avg_ndcg_at_k']:.3f}\",\n",
        "        \"Latencia B√∫squeda (ms)\": f\"{weaviate_results['avg_metrics']['avg_search_time']*1000:.1f}\",\n",
        "        \"Tiempo Total (ms)\": f\"{weaviate_results['avg_metrics']['avg_total_time']*1000:.1f}\"\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"üìä TABLA COMPARATIVA - QDRANT VS WEAVIATE\")\n",
        "print(\"=\" * 80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Mostrar tabla con Rich para mejor visualizaci√≥n\n",
        "table = Table(title=\"Comparaci√≥n Qdrant vs Weaviate\")\n",
        "table.add_column(\"Sistema\", style=\"cyan\")\n",
        "table.add_column(\"P@5\", justify=\"right\")\n",
        "table.add_column(\"R@5\", justify=\"right\")\n",
        "table.add_column(\"nDCG@5\", justify=\"right\")\n",
        "table.add_column(\"Latencia B√∫squeda (ms)\", justify=\"right\")\n",
        "table.add_column(\"Tiempo Total (ms)\", justify=\"right\")\n",
        "\n",
        "for _, row in comparison_df.iterrows():\n",
        "    table.add_row(\n",
        "        row[\"Sistema\"],\n",
        "        row[\"P@5\"],\n",
        "        row[\"R@5\"],\n",
        "        row[\"nDCG@5\"],\n",
        "        row[\"Latencia B√∫squeda (ms)\"],\n",
        "        row[\"Tiempo Total (ms)\"]\n",
        "    )\n",
        "\n",
        "console.print(table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPej1PKpOavt"
      },
      "source": [
        "## 11. An√°lisis Comparativo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LuMKgvxOavu",
        "outputId": "0754c2c1-d26d-43a1-f1ba-343875056371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## AN√ÅLISIS COMPARATIVO: QDRANT VS WEAVIATE\n",
            "\n",
            "### M√©tricas de Calidad:\n",
            "- **Precision@5**: Qdrant (0.220) vs Weaviate (0.220)\n",
            "- **Recall@5**: Qdrant (1.000) vs Weaviate (1.000)\n",
            "- **nDCG@5**: Qdrant (0.926) vs Weaviate (0.926)\n",
            "\n",
            "### Rendimiento:\n",
            "- **Latencia de B√∫squeda**: Qdrant (28.0ms) vs Weaviate (9.0ms)\n",
            "- **Tiempo Total**: Qdrant (5713.3ms) vs Weaviate (3639.8ms)\n",
            "\n",
            "### Conclusiones:\n",
            "\n",
            "**Calidad de Resultados:**\n",
            "Ambos sistemas muestran rendimientos similares en t√©rminos de calidad, lo cual es esperado dado que:\n",
            "- Utilizan los mismos embeddings (all-MiniLM-L6-v2)\n",
            "- Procesan el mismo corpus de documentos\n",
            "- Implementan b√∫squeda por similitud coseno\n",
            "\n",
            "**Rendimiento y Latencia:**\n",
            "Weaviate muestra mejor rendimiento en b√∫squeda.\n",
            "- Qdrant utiliza √≠ndices HNSW optimizados para consultas r√°pidas\n",
            "- Weaviate (simulado) tiene overhead m√≠nimo pero en implementaci√≥n real ser√≠a diferente\n",
            "\n",
            "**Facilidad de Uso:**\n",
            "- **Qdrant**: API m√°s simple, configuraci√≥n directa, ideal para casos de uso espec√≠ficos\n",
            "- **Weaviate**: Esquemas m√°s ricos, mejor manejo de metadatos complejos, GraphQL integrado\n",
            "\n",
            "**Recomendaci√≥n:**\n",
            "- **Qdrant**: Mejor para aplicaciones que priorizan velocidad y simplicidad\n",
            "- **Weaviate**: Mejor para aplicaciones que requieren esquemas complejos y consultas avanzadas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# An√°lisis detallado\n",
        "analysis = f\"\"\"\n",
        "## AN√ÅLISIS COMPARATIVO: QDRANT VS WEAVIATE\n",
        "\n",
        "### M√©tricas de Calidad:\n",
        "- **Precision@5**: Qdrant ({qdrant_results['avg_metrics']['avg_precision_at_k']:.3f}) vs Weaviate ({weaviate_results['avg_metrics']['avg_precision_at_k']:.3f})\n",
        "- **Recall@5**: Qdrant ({qdrant_results['avg_metrics']['avg_recall_at_k']:.3f}) vs Weaviate ({weaviate_results['avg_metrics']['avg_recall_at_k']:.3f})\n",
        "- **nDCG@5**: Qdrant ({qdrant_results['avg_metrics']['avg_ndcg_at_k']:.3f}) vs Weaviate ({weaviate_results['avg_metrics']['avg_ndcg_at_k']:.3f})\n",
        "\n",
        "### Rendimiento:\n",
        "- **Latencia de B√∫squeda**: Qdrant ({qdrant_results['avg_metrics']['avg_search_time']*1000:.1f}ms) vs Weaviate ({weaviate_results['avg_metrics']['avg_search_time']*1000:.1f}ms)\n",
        "- **Tiempo Total**: Qdrant ({qdrant_results['avg_metrics']['avg_total_time']*1000:.1f}ms) vs Weaviate ({weaviate_results['avg_metrics']['avg_total_time']*1000:.1f}ms)\n",
        "\n",
        "### Conclusiones:\n",
        "\n",
        "**Calidad de Resultados:**\n",
        "Ambos sistemas muestran rendimientos similares en t√©rminos de calidad, lo cual es esperado dado que:\n",
        "- Utilizan los mismos embeddings (all-MiniLM-L6-v2)\n",
        "- Procesan el mismo corpus de documentos\n",
        "- Implementan b√∫squeda por similitud coseno\n",
        "\n",
        "**Rendimiento y Latencia:**\n",
        "{'Qdrant' if qdrant_results['avg_metrics']['avg_search_time'] < weaviate_results['avg_metrics']['avg_search_time'] else 'Weaviate'} muestra mejor rendimiento en b√∫squeda.\n",
        "- Qdrant utiliza √≠ndices HNSW optimizados para consultas r√°pidas\n",
        "- Weaviate (simulado) tiene overhead m√≠nimo pero en implementaci√≥n real ser√≠a diferente\n",
        "\n",
        "**Facilidad de Uso:**\n",
        "- **Qdrant**: API m√°s simple, configuraci√≥n directa, ideal para casos de uso espec√≠ficos\n",
        "- **Weaviate**: Esquemas m√°s ricos, mejor manejo de metadatos complejos, GraphQL integrado\n",
        "\n",
        "**Recomendaci√≥n:**\n",
        "- **Qdrant**: Mejor para aplicaciones que priorizan velocidad y simplicidad\n",
        "- **Weaviate**: Mejor para aplicaciones que requieren esquemas complejos y consultas avanzadas\n",
        "\"\"\"\n",
        "\n",
        "print(analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIgX4fDQOavu"
      },
      "source": [
        "## 12. Bonus: Filtrado por Metadatos y Consultas H√≠bridas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmNbiMq2Oavu",
        "outputId": "6ed9471f-7ede-46fe-8815-89951c1bc491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ BONUS: Ejemplos de Filtrado por Metadatos y Consultas H√≠bridas\\n\n",
            "============================================================\n",
            "EJEMPLO 1: B√∫squeda filtrada por categor√≠a 'medicina'\n",
            "============================================================\n",
            "\\nüîπ QDRANT:\n",
            "Pregunta: ¬øQu√© aplicaciones tiene la tecnolog√≠a en salud?\n",
            "Filtro: {'category': 'medicina'}\n",
            "Respuesta: La IA is applied in diagnostics for imagens, analogues of genomas and temprana de enfermedades. The algorithms of aprendizaje autom√°tico can identify patrons in radiografas, resonancias magn√©ticas and tomografas computarizadas.\n",
            "Documentos encontrados: [17, 6, 1]\n",
            "Fuentes: ['Revista Mente Abierta', 'Revista Salud Digital', 'Psicolog√≠a Cl√≠nica']\n",
            "\\nüîπ WEAVIATE:\n",
            "Pregunta: ¬øQu√© aplicaciones tiene la tecnolog√≠a en salud?\n",
            "Filtro: {'category': 'medicina'}\n",
            "Respuesta: La IA is applied in diagnostics for imagens, analogues of genomas and temprana de enfermedades. The algorithms of aprendizaje autom√°tico can identify patrons in radiografas, resonancias magn√©ticas and tomografas computarizadas.\n",
            "Documentos encontrados: [17, 6, 1]\n",
            "Fuentes: ['Revista Mente Abierta', 'Revista Salud Digital', 'Psicolog√≠a Cl√≠nica']\n"
          ]
        }
      ],
      "source": [
        "print(\"üéØ BONUS: Ejemplos de Filtrado por Metadatos y Consultas H√≠bridas\\\\n\")\n",
        "\n",
        "# Ejemplo 1: Filtro por categor√≠a\n",
        "print(\"=\" * 60)\n",
        "print(\"EJEMPLO 1: B√∫squeda filtrada por categor√≠a 'medicina'\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "question1 = \"¬øQu√© aplicaciones tiene la tecnolog√≠a en salud?\"\n",
        "filters1 = {\"category\": \"medicina\"}\n",
        "\n",
        "# Qdrant\n",
        "print(\"\\\\nüîπ QDRANT:\")\n",
        "qdrant_filtered = qdrant_rag.query(question1, k=3, filters=filters1)\n",
        "print(f\"Pregunta: {question1}\")\n",
        "print(f\"Filtro: {filters1}\")\n",
        "print(f\"Respuesta: {qdrant_filtered['answer']}\")\n",
        "print(f\"Documentos encontrados: {[r['doc_id'] for r in qdrant_filtered['search_results']]}\")\n",
        "print(f\"Fuentes: {qdrant_filtered['sources']}\")\n",
        "\n",
        "# Weaviate\n",
        "print(\"\\\\nüîπ WEAVIATE:\")\n",
        "weaviate_filtered = weaviate_rag.query(question1, k=3, filters=filters1)\n",
        "print(f\"Pregunta: {question1}\")\n",
        "print(f\"Filtro: {filters1}\")\n",
        "print(f\"Respuesta: {weaviate_filtered['answer']}\")\n",
        "print(f\"Documentos encontrados: {[r['doc_id'] for r in weaviate_filtered['search_results']]}\")\n",
        "print(f\"Fuentes: {weaviate_filtered['sources']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf-6kx2QOavu",
        "outputId": "379aaebe-4206-4d6c-8000-edd710cf7318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n============================================================\n",
            "EJEMPLO 2: B√∫squeda filtrada por rango de fechas (2025)\n",
            "============================================================\n",
            "\\nüîπ QDRANT:\n",
            "Pregunta: ¬øCu√°les son las tendencias tecnol√≥gicas recientes?\n",
            "Filtro: {'date': ('2025-01-01', '2025-12-31')}\n",
            "Respuesta: No encontr√© informaci√≥n relevante.\n",
            "Documentos encontrados: []\n",
            "Fechas: []\n",
            "Fuentes: []\n",
            "\\nüîπ WEAVIATE:\n",
            "Pregunta: ¬øCu√°les son las tendencias tecnol√≥gicas recientes?\n",
            "Filtro: {'date': ('2025-01-01', '2025-12-31')}\n",
            "Respuesta: nTexto: Importance de los policadoresnTexto: Abejas, mariposas y aves ayudan en la reproducci√≥n de plantas y producci√≥n de alimentos. Sin policadores, muchos cultivos no podan\n",
            "Documentos encontrados: [23, 8, 30, 20, 26]\n",
            "Fechas: ['2025-07-17', '2025-06-01', '2025-08-01', '2025-05-01', '2025-03-10']\n",
            "Fuentes: ['Tech Diario', 'Econom√≠a Sostenible', 'Aprendizaje Autom√°tico Hoy', 'Biodiversidad Global', 'Seguridad Digital Hoy']\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo 2: Filtro por rango de fechas\n",
        "print(\"\\\\n\" + \"=\" * 60)\n",
        "print(\"EJEMPLO 2: B√∫squeda filtrada por rango de fechas (2025)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "question2 = \"¬øCu√°les son las tendencias tecnol√≥gicas recientes?\"\n",
        "filters2 = {\"date\": (\"2025-01-01\", \"2025-12-31\")}\n",
        "\n",
        "# Qdrant\n",
        "print(\"\\\\nüîπ QDRANT:\")\n",
        "qdrant_date_filtered = qdrant_rag.query(question2, k=5, filters=filters2)\n",
        "print(f\"Pregunta: {question2}\")\n",
        "print(f\"Filtro: {filters2}\")\n",
        "print(f\"Respuesta: {qdrant_date_filtered['answer']}\")\n",
        "print(f\"Documentos encontrados: {[r['doc_id'] for r in qdrant_date_filtered['search_results']]}\")\n",
        "print(f\"Fechas: {[docs[r['doc_id']-1]['date'] for r in qdrant_date_filtered['search_results']]}\")\n",
        "print(f\"Fuentes: {qdrant_date_filtered['sources']}\")\n",
        "\n",
        "# Weaviate\n",
        "print(\"\\\\nüîπ WEAVIATE:\")\n",
        "weaviate_date_filtered = weaviate_rag.query(question2, k=5, filters=filters2)\n",
        "print(f\"Pregunta: {question2}\")\n",
        "print(f\"Filtro: {filters2}\")\n",
        "print(f\"Respuesta: {weaviate_date_filtered['answer']}\")\n",
        "print(f\"Documentos encontrados: {[r['doc_id'] for r in weaviate_date_filtered['search_results']]}\")\n",
        "print(f\"Fechas: {[docs[r['doc_id']-1]['date'] for r in weaviate_date_filtered['search_results']]}\")\n",
        "print(f\"Fuentes: {weaviate_date_filtered['sources']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri-AyAIvOavu",
        "outputId": "84634927-6a8d-4f5f-bcc7-4fa4fc3ba442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n============================================================\n",
            "EJEMPLO 3: Consulta h√≠brida (texto + categor√≠a)\n",
            "============================================================\n",
            "\\nüîπ QDRANT:\n",
            "Pregunta: ¬øQu√© informaci√≥n hay sobre salud?\n",
            "Filtro: {'category': 'salud'}\n",
            "Respuesta: Ttulo: Alimentos ricos en fibranTexto: Legumbres, frutas, cereales integrales y semillas favorecen la digesti√≥n y la salud intestinal. Una dieta rica en fibra puede prevenir enfermedades cardiovasculares.nnTtulo: Ventajas del ejercicio regularnTexto: Reduce el riesgo de enfermedades, mejora el estado de √°nimo y fortalece\n",
            "Documentos encontrados: [21, 27, 3]\n",
            "Categor√≠as: ['salud', 'salud', 'salud']\n",
            "Fuentes: ['Salud Activa', 'Portal Nutrici√≥n y Vida', 'Gu√≠a Nutricional']\n",
            "\\nüîπ WEAVIATE:\n",
            "Pregunta: ¬øQu√© informaci√≥n hay sobre salud?\n",
            "Filtro: {'category': 'salud'}\n",
            "Respuesta: Ttulo: Alimentos ricos en fibranTexto: Legumbres, frutas, cereales integrales y semillas favorecen la digesti√≥n y la salud intestinal. Una dieta rica en fibra puede prevenir enfermedades cardiovasculares.nnTtulo: Ventajas del ejercicio regularnTexto: Reduce el riesgo de enfermedades, mejora el estado de √°nimo y fortalece\n",
            "Documentos encontrados: [21, 27, 3]\n",
            "Categor√≠as: ['salud', 'salud', 'salud']\n",
            "Fuentes: ['Salud Activa', 'Portal Nutrici√≥n y Vida', 'Gu√≠a Nutricional']\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo 3: Consulta h√≠brida (texto + m√∫ltiples filtros)\n",
        "print(\"\\\\n\" + \"=\" * 60)\n",
        "print(\"EJEMPLO 3: Consulta h√≠brida (texto + categor√≠a)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "question3 = \"¬øQu√© informaci√≥n hay sobre salud?\"\n",
        "filters3 = {\"category\": \"salud\"}  # Solo documentos de categor√≠a salud\n",
        "\n",
        "# Qdrant\n",
        "print(\"\\\\nüîπ QDRANT:\")\n",
        "qdrant_hybrid = qdrant_rag.query(question3, k=3, filters=filters3)\n",
        "print(f\"Pregunta: {question3}\")\n",
        "print(f\"Filtro: {filters3}\")\n",
        "print(f\"Respuesta: {qdrant_hybrid['answer']}\")\n",
        "print(f\"Documentos encontrados: {[r['doc_id'] for r in qdrant_hybrid['search_results']]}\")\n",
        "print(f\"Categor√≠as: {[r['category'] for r in qdrant_hybrid['search_results']]}\")\n",
        "print(f\"Fuentes: {qdrant_hybrid['sources']}\")\n",
        "\n",
        "# Weaviate\n",
        "print(\"\\\\nüîπ WEAVIATE:\")\n",
        "weaviate_hybrid = weaviate_rag.query(question3, k=3, filters=filters3)\n",
        "print(f\"Pregunta: {question3}\")\n",
        "print(f\"Filtro: {filters3}\")\n",
        "print(f\"Respuesta: {weaviate_hybrid['answer']}\")\n",
        "print(f\"Documentos encontrados: {[r['doc_id'] for r in weaviate_hybrid['search_results']]}\")\n",
        "print(f\"Categor√≠as: {[r['category'] for r in weaviate_hybrid['search_results']]}\")\n",
        "print(f\"Fuentes: {weaviate_hybrid['sources']}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}